## Data Analytics Python Learnings

## Data Analytics

## Interpreting Data with Python

Data Analytics is the detection, interpretation, and communication of meaningful patterns in data.

Learn fundamental objectives around representing, processing, and shaping data for analysis.

### Representing, Processing, and Preparing Data
Data science and data modeling are fast emerging as crucial capabilities that every enterprise and every technologist must possess these days. As the process of actually constructing models becomes democratized, the general view is shifting toward using the right data and using the data right. In this course, Representing, Processing, and Preparing Data, you will gain the ability to correctly represent information from your domain as numeric data, and get it into a form where the full capabilities of models can be leveraged. First, you will learn how outliers and missing data can be dealt with in a theoretically sound manner. Next, you will discover how to use spreadsheets, programming languages and relational databases to work with your data. You will see the different types of data that you may deal with in the real world and how you can collect and integrate data to a common destination to eliminate silos. Finally, you will round out the course by working with visualization tools that allow every member of an enterprise to work with data and extract meaningful insights. When you are finished with this course, you will have the skills and knowledge to use the right data sources, cope with data quality issues and choose the right technologies to extract insights from your enterprise data.
###### Understanding Data Cleaning and Preparation Techniques
###### Preparing Data for Analysis Using Spreadsheets and Python
###### Collecting Data to Extract Insights
###### Loading and Processing Data Using Relational Databases
###### Representing Insights Obtained from Data

### Combining and Shaping Data
Connecting the dots between data from different sources is becoming the most sought-after skill these days for everyone ranging from business professionals to data scientists. In this course, Combining and Shaping Data, you will gain the ability to connect the dots by pulling together data from disparate sources and shaping it so that extracting connections and relationships becomes relatively easy. First, you will learn how the most common constructs in shaping and combining data stay the same across spreadsheets, programming languages, and databases. Next, you will discover how to use joins and vlookups to obtain wide datasets, and then use pivots to shape that into long form. You will then see how both long and wide data can be aggregated to obtain higher level insights. You will work with Excel spreadsheets and SQL as well as Python. Finally, you will round out the course by integrating data from a variety of sources and working with streaming data, which helps your enterprise gain real-time insights into the world around you. When you are finished with this course, you will have the skills and knowledge to pull together data from disparate sources, including from streaming sources, to construct integrated data models that truly connect the dots.
###### Exploring Techniques to Combine and Shape Data
###### Combining and Shaping Data Using Spreadsheets
###### Combining and Shaping Data Using SQL
###### Combining and Shaping Data Using Python
###### Integrating Data from Disparate Sources into a Data Warehouse
###### Working with Streaming Data Using a Data Warehouse

Learn to apply descriptive statistics to data, and design experiments to further your analysis.

### Summarizing Data and Deducing Probabilities
Data science and data modeling are fast emerging as crucial capabilities that every enterprise and every technologist must possess these days. Increasingly, different organizations are using the same models and the same modeling tools, so what differs is how those models are applied to the data. So, it is really important that you know your data well. In this course, Summarizing Data and Deducing Probabilities, you will gain the ability to summarize your data using univariate, bivariate, and multivariate statistics in a range of technologies. First, you will learn how measures of mean and central tendency can be calculated in Microsoft Excel and Python. Next, you will discover how to use correlations and covariances to explore pairwise relationships. You will then see how those constructs can be generalized to multiple variables using covariance and correlation matrices. You will understand and apply Bayes' Theorem, one of the most powerful and widely-used results in probability, to build a robust classifier. Finally, you will use Seaborn, a visualization library, to represent statistics visually.   When you are finished with this course, you will have the skills and knowledge to use univariate, bivariate, and multivariate descriptive statistics from Excel and Python in order to find relationships and calculate probabilities.
###### Understanding Descriptive Statistics for Data Analysis
###### Performing Exploratory Data Analysis in Spreadsheets
###### Summarizing Data and Deducing Probabilities Using Python
###### Understanding and Applying Bayes' Rule
###### Visualizing Probabilistic and Statistical Data Using Seaborn

### Experimental Design for Data Analysis
Providing crisp, clear, actionable points-of-view to senior executives is becoming an increasingly important role of data scientists and data professionals these days. Now, a point-of-view must represent a hypothesis, ideally backed by data. In this course, Experimental Design for Data Analysis, you will gain the ability to construct such hypotheses from data and use rigorous frameworks to test whether they hold true. First, you will learn how inferential statistics and hypothesis testing form the basis of data modeling and machine learning. Next, you will discover how the process of building machine learning models is akin to that of designing an experiment and how training and validation techniques help rigorously evaluate the results of such experiments. Then, you will round out the course by studying various forms of cross-validation, including both singular and iterative techniques to cope with independent, identically distributed data and grouped data. Finally, you will also learn how you can refine your models using these techniques with hyperparameter tuning. When you’re finished with this course, you will have the skills and knowledge to build and evaluate models, specifically including machine learning models, using rigorous cross-validation frameworks and hyperparameter tuning.
###### Designing an Experiment for Data Analysis
###### Building and Training a Machine Learning Model
###### Understanding and Overcoming Common Problems in Data Modeling
###### Leveraging Different Validation Strategies in Data Modeling
###### Tuning Hyperparameters Using Cross Validation Scores

Learn to apply common statistical models to business problems, and to recognize factors that impact your communication of findings.

### Interpreting Data with Statistical Models
Data is everywhere, from the newspaper you read on the subway to the report you are using to analyze yesterday's stock market performance. In this course, Interpreting Data with Statistical Models, you will gain the ability to effectively understand how to tackle problems that appear at your work, understand which is the right statistical analysis to use, and how to interpret the results to obtain insights. First, you will learn the very basics of statistics. Next, you will discover hypothesis testing to compare variables. Finally, you will explore how to make multiple comparisons and detect functional relationships with ANOVA and Regression. When you’re finished with this course, you will have the skills and knowledge of data analysis and statistical models needed to make your data speak for itself.
###### Thinking Like a Statistician
###### Testing a Hypothesis
###### Comparing Categorical Values with Frequency Analysis
###### Analyzing Experiments with ANOVA
###### Comparing Groups and Effects with ANOVA
###### Predicting Linear Relationships with Regression
###### Predicting Non-linear Relationships with Regression

### Communicating Data Insights
Providing crisp, clear, actionable points-of-view to senior executives is becoming an increasingly important role of data scientists and data professionals these days. In this course, Communicating Data Insights you will gain the ability to summarize complex information into such clear and actionable insights. First, you will learn how to sum up the important descriptive statistics from any numeric dataset. Next, you will discover how to build and use specialized visual representations such as candlestick charts, Sankey diagrams and funnel charts in Python. You will then see how the data behind such representations can now be fed in from enterprise-wide sources such as data warehouses and ETL pipelines. Finally, you will round out the course by working with data residing in different public cloud platforms, and even in a hybrid environment, that is with some of it on-premise and some of it on the cloud. When you’re finished with this course, you will have the skills and knowledge to pull together data from disparate sources and use nifty visualizations to convey crisp, actionable points-of-view to a senior executive audience.
###### Communicating Insights from Statistical Data
###### Communicating Insights from Business Data
###### Visualizing Distributions and Relationships in Data
###### Integrating Data in a Multi-cloud Environment
###### Integrating Data in a Hybrid Environment

## Python for Data Analysts
One of the most pervasive uses of Python is to analyze data. This skill is for those who want to leverage the power of Python in data treatment and analysis.

Create your first Python analytics solution, and learn to use common Python environments like IDEs and notebooks.

### Building Your First Python Analytics Solution
Python has exploded in popularity in recent years, largely because it makes analyzing and working with data so incredibly simple. Despite its great success as a prototyping tool, Python is still relatively unproven for large, enterprise-scale development.   In this course, Building your First Python Analytics Solution you will gain the ability to identify and use the right development and execution environment for your enterprise. First, you will learn how Jupyter notebooks, despite their immense popularity, are not quite as robust as fully-fledged Integrated Development Environments, or IDEs. Next, you will discover how different execution environments offer alternative ways of configuring Python libraries, and specifically how the two most popular, Conda and Pip, stack up against each other. You will also explore several different development environments including IDLE, PyCharm, Eclipse, and Spyder. Finally, you will round out your knowledge by running Python on the major cloud environments, including AWS, Microsoft Azure, and the GCP. When you’re finished with this course, you will have the skills and knowledge to identify the correct development and execution environments for Python in your organizational context.
###### Getting Started with Python for Analytics
###### Working with Python Using Anaconda
###### Working with Python Using Other IDEs
###### Working with Python on the Cloud

### Python for Data Analysts
Python has exploded in popularity in recent years and has emerged as the technology of choice for data analysts and data scientists. In this course, Python for Data Analysts, you will gain the ability to write Python programs and utilize fundamental building blocks of programming and data analysis. First, you will learn how programming languages such as Python, spreadsheets such as Microsoft Excel, and SQL-based technologies such as databases differ from each other, and also how they inter-operate. Next, you will plunge into Python programming, installing Python and getting started with simple programs. You will then understand the ways in which variables are used to hold data, and how simple and complex data types in Python differ in their semantics. Finally, you will round out your knowledge by working with conditional evaluation using if statements, loops and functions. You will learn how Python treats functions as first-class entities, a key enabler of functional programming. When you’re finished with this course, you will have the skills and knowledge to identify situations when Python is the right choice for you, and to implement simple but solid programs using Python.
###### Getting Started with Python for Data Analysis
###### Leveraging Built-in Functions and Complex Data Types
###### Using Python for Complex Interconnected Calculations
###### Implementing Code Reuse Using Functions in Python
###### Loading and Saving Data Using Python

### Programming Python Using an IDE
Learning and becoming proficient with Python is one of the best decisions a coder can make. The simplicity of Python, along with the many libraries available make it one of the most productive languages you can use. This course, Programming Python Using an IDE, will help you use an IDE to take your coding skills one level higher! First, you will explore the selection of popular IDEs and how they can help you improve your productivity. Next, you will learn about the many features that make IDEs great for creating applications including syntax highlighting, refactoring, code checking, and more. You will also discover some other features that help you run, debug, unit test, and source control your code. Finally, you will see how some IDEs have features that are meant for scientific Python and creating data science applications. By the end of this course, you will know and understand how IDEs can help you be a more productive developer.
###### Programming Python Using an IDE! But Why? And Which One?
###### Improving Your Productivity Programming in Python with an IDE
###### Leveraging a Python IDE for Data Science

### Create and Share Analytics with Jupyter Notebooks
Python has exploded in popularity in recent years, largely because it makes analyzing and working with data so incredibly simple. Jupyter is an execution environment rather than a fully-fledged IDE, but even so, notebooks have various important features that are worth understanding thoroughly. In this course, Create and Share Analytics with Jupyter Notebooks, you will learn how Jupyter notebooks are a key driver of Python’s popularity, by providing an incredibly intuitive, interactive environment for executing Python programs. First, you will learn how to get up and running with Jupyter notebooks, and how best to leverage features such as markdown to enhance the readability of your code. Next, you will discover how more advanced features such as magic functions work, and how the next generation offering from Jupyter, named JupyterLab goes even further towards a fully-fledged development environment. Finally, you will round out your knowledge by working with cloud-hosted Jupyter notebooks on each of the major cloud platforms. When you’re finished with this course, you will have the skills and knowledge to leverage the full power of Jupyter notebooks and Jupyterlab, particularly in the context of cloud-hosted notebooks for distributed and collaborative use-cases.
###### Getting Started with Jupyter Notebooks
###### Understanding Jupyter Notebooks
###### Creating Shareable Analyses in Jupyter Notebooks
###### Working with Cloud-hosted Jupyter Notebooks

Apply Python to specific parts of the analytics workflow. Learn how to load, clean, and visualize data.

### Importing Data: Python Data Playbook
Python is one of the most powerful and widely used languages to work with data. In this course, Importing Data: Python Data Playbook, you will learn foundational knowledge and gain the ability to import data from multiple different file formats, including: text, tabular data, binary formats as well as from databases. First, you will learn how to import text and CSV files. Next, you will discover how to import data from JSON, XML, SAS, Stata, HDF5, Matlab, Pickle files, and more. Finally, you will explore how to import relational data from databases, including: SQLite, MySQL, and PostgreSQL. When you're finished with this course, you will have the skills and knowledge of importing data into Python needed to analyze, visualize, and in general work with data.
###### Importing Text Data into Python Using NumPy
###### Importing CSV Data into Python Using csv and pandas
###### Import Data into Python from JSON and XML Files
###### Import Data into Python from Excel Files
###### Import Data into Python from Common Binary Data File Formats
###### Import Data into Python from Relational Databases

### Data Wrangling with Python 3
Machine Learning and Data analytics in general follows the garbage-in/garbage-out principle. If you want to learn from or predict based on your data, you need to make sure that data is well constructed and cleaned. This course, Data Wrangling with Python 3, is aimed at helping you do exactly that. First, you’ll see how to merge data from different sources using the methods concat, append, and merge. Next, you’ll discover how to combine data into groups. The primary function used here is groupby. In the next two sections, you’ll explore how to transform and normalize data. You’ll learn why these processes are necessary, and then proceed to see how they work in practice. Finally, you’ll examine important processes such as One Hot Encoding, which enables further processing during data analysis. When you’re finished with this course, you’ll have thorough knowledge of data wrangling which will help you immensely during your data analysis and machine learning projects.
###### Concatenating and Merging Data from Different Sources
###### Combining Data into Groups
###### Normalizing Data with Pandas
###### Reshaping Data with Python
###### Data Encoding with Python

### Cleaning Data: Python Data Playbook
At the core of any successful project that involves a real world dataset is a thorough knowledge of how to clean that dataset from missing, bad, or inaccurate data. In this course, Cleaning Data: Python Data Playbook, you'll learn how to use pandas to clean a real world dataset. First, you'll learn how to understand, view, and explore the data you have. Next, you'll explore how to access just the data that you want to keep in your dataset. Finally, you'll discover different ways to handle bad and missing data. When you're finished with this course, you'll have a foundational knowledge of cleaning real world datasets with pandas that will help you as you move forward to working on real world data science or machine learning problems.
###### Understanding Your Data
###### Removing and Fixing Columns with pandas
###### Indexing and Filtering Datasets
###### Handling Bad, Missing, and Duplicate Data

### Pygal 2: Python Data Playbook
Vector image formats such as SVG possess many important advantages over scalar formats such as PNG and JPEG. Using SVG, you can build high-quality, compact visualizations that render on low-resolution devices and that can be scaled, zoomed, and moved without distortion. In this course, Pygal: Python Data Playbook, you will gain the ability to construct an array of visualizations and render them to SVG format using Pygal. First, you will learn the advantages of working with Pygal for building SVGs and understand the niche that Pygal occupies relative to other visualization packages such as Matplotlib, Seaborn, Bokeh, and Plotly. Next, you will discover how to build an array of visualizations in Pygal, from in-memory as well as file data. You will then construct a visualization including simple charts such as Line, Tree, and Bar graphs, as well as specialized types like TreeMaps and Sparklines. You will understand the different types of Styles and Configurations that can be used to govern chart appearance. You will work with built-in, parametric, and custom styles, as well as Chart, Serie, and Value configurations. Finally, you will explore how to render Pygal visualizations to a range of image and non-image formats, including XML element trees and base64 encoded formats for online transfer. You will round out the course by building a web application using the Flask microframework in order to render and serve Pygal charts. When you are finished with this course, you will have the skills and knowledge of building and rendering visualizations in Pygal needed to effectively harness the many advantages of the Scalable Vector Graphics format.
###### Getting Data into Pygal
###### Plotting Basic Pygal Charts
###### Visualizing Complex Data with Advanced Charts
###### Rendering Out Charts

Extend your abilities to scraping data from the web and uses databases with Python.

### Understanding Databases with SQLAlchemy 1: Python Data Playbook
Databases are an integral part of data science, and every programmer that interacts with data needs to be able to work with a database. In this course, Understanding Databases with SQLAlchemy 1: Python Data Playbook, you will learn foundational knowledge to work with databases using SQLAlchemy. First, you will see how to perform queries. Next, you will discover how to create databases and tables and populate them with data. Finally, you will explore how to manipulate the data you inserted and queried. When you are finished with this course, you will have the skills and knowledge of interacting with databases needed to successfully work with your database using Python with SQLAlchemy.
###### Up and Running with SQLAlchemy
###### Querying with SQLAlchemy
###### Creating Your Database
###### Manipulating Your Database

### Web Scraping: Python Data Playbook
Scrape data from a static web page with BeautifulSoup4 and turn it into a compelling graphical data story in a Jupyter Notebook. In this course, Web Scraping: The Python Data Playbook, you will gain the ability to scrape data and present it graphically. First, you will learn to scrape using the requests module and BeautifulSoup###### Next, you will discover how to write a trustworthy scraping module backed by a unit test. Finally, you will explore how to turn the columns of data in a graphical story that will change the opinions of your colleagues. When you're finished with this course, you will have the skills and knowledge of web scraping needed to create a graphically compelling Jupyter Notebook without the use of an API.
###### Setting Up BeautifulSoup
###### Understanding Your Scraped Data
###### Making Scraped Data Usable

### Leveraging Online Resources for Python Analytics
As data science and data analytics become ever more popular and more specialized, the number and variety of tools and technologies out there can often seem overwhelming. In this course, Leveraging Online Resources for Python Analytics, you will gain the ability to find resources that can help you to correctly frame and solve your problem. First, you will survey some of the important visualization libraries, machine learning and deep learning frameworks, and cloud-based solutions out there. Next, you will discover the benefits of using a tool like BigML, which is a platform for building ML models that abstracts away much of the underlying complexity. Democratization of ML is an important trend today, and technologies like BigML are at the forefront of that trend. You will see, for instance, how BigML seamlessly integrates visualizations known as partial dependency plots, which combine the results of large numbers of ML predictions into an easily understandable form so that you can understand exactly what your ML model is doing. Finally, you will round out your knowledge by working with Google Colab, a free web-based way to build models. The models are hosted in Jupyter notebooks that reside on Google Drive and run on virtual machines in the cloud. When you’re finished with this course, you will have the skills and knowledge to quickly and efficiently identify valuable online resources and libraries that will help you on your journey as a data science practitioner.
###### Getting Started with Python Analytics
###### Leveraging Online Resources for Python Analytics with BigML
###### Working with Interactive Environment Using Google Colab

## Web Scraping with Python
There are times in which you need data but there is no API (application programming interface) to be found. Web scraping is the process of extracting data from web sites via programmatic means. This skill will teach you how to scrape websites for data using Python.

Describe the process of scraping data from the web, explain the legal factors, and scrape data from a web page with BeautifulSoup.

### Exploring Web Scraping with Python
The web is a giant database and when there’s no API, you can still retrieve the data through web scraping. In this course, Exploring Web Scraping with Python, you will learn foundational knowledge of web scraping and how to use Python’s rich set of scraping capabilities. First, you will learn how to download and extract data with Requests and Beautiful Soup. Next, you will discover how to build a spider in about 20 lines of code with Scrapy. Finally, you will explore how to use a robotic browser to solve advanced web scraping challenges. When you are finished with this course, you will know “SQL for web scraping,” and have the skills and knowledge of content selectors and Python needed to start your own website scraping projects.
###### Why Scrape the Web?
###### The Web Scraping Process
###### CSS Selectors and XPath
###### Is Web Scraping Legal? Is it Ethical?
###### Web Scraping Basics with Python
###### Building a Web Spider with Scrapy
###### Advanced Web Scraping with Selenium and Requests-html

### Scraping Your First Web Page with Python
Web scraping is an important technique that is widely used as the first step in many workflows in data mining, information retrieval, and text-based machine learning. In this course, Scraping your First Web Page with Python, you will gain the ability to apply different scraping techniques including Beautiful Soup, and Scrapy. First, you will learn and use various HTTP client libraries such as Requests, httplib2, and urllib to download HTML content. Next, you will discover how Beautiful Soup is an extremely popular Python library that does better than regex in important ways. You will see how Beautiful Soup fixes up badly formed HTML, and constructs a nice parse tree that can be traversed and queried. Finally, you will add to your toolkit the knowledge of Scrapy, which is a full-fledged web scraping framework that combines the steps of retrieving and parsing web content and does so at production-scale. When you’re finished with this course, you will have the skills and knowledge to identify the relative strengths and use-cases of different web retrieval and scraping technologies such as regular expressions, Beautiful Soup, and Scrapy.
###### Getting Started with Web Scraping
###### Working with the Parse Tree in BeautifulSoup
###### Selecting Elements Using the Scrapy Shell
###### Scraping Web Sites Using Scrapy Spiders

Scrape data from a web page extract with specific page elements using BeautifulSoup.

### Extracting Data from HTML with BeautifulSoup
Web scraping is an important technique that is widely used as the first step in many workflows in data mining, information retrieval, and text-based machine learning. In this course, Extracting Data from HTML with BeautifulSoup* you will gain the ability to build robust, maintainable web scraping solutions using the Beautiful Soup library in Python. First, you will learn how regular expressions can be used to scrape web content, and how Beautiful Soup does better in important ways. Next, you will discover how Beautiful Soup parses HTML from web content, fixes up badly-formed tags, and builds a clean, easily traversable parse tree. You will then see how that parse tree can be used in order to find and retrieve specific patterns. Finally, you will round out your knowledge by leveraging advanced features of beautiful soup such as working with CSS and XPath. When you’re finished with this course, you will have the skills and knowledge to implement robust web scraping using Beautiful Soup.
###### Getting Started with BeautifulSoup
###### Navigating the Parse Tree
###### Searching for Elements in the Parse Tree
###### Leveraging Advanced Features of BeautifulSoup

### Scraping Media from the Web with Python
Unlike simple text-based scraping, scraping media from the web has differences that you need to be aware of. In this course, Scraping Media from the Web with Python, you’ll gain the ability to identify web media links and analyze the best method to acquire this data. First, you’ll explore different content types and extraction methods. Next, you’ll discover various tools to download the media. Finally, you’ll learn how to process the media once you have acquired it. When you’re finished with this course, you’ll have the skills and knowledge of scraping web media needed to successfully identify, analyze, download, and process web media based data.
###### Extracting Media Links from a Web Page
###### Downloading Media Files
###### Processing Web Media Files

Create a spider to collect data across multiple pages and scrape a dynamically-rendered web page.

### Crawling the Web with Python 3 and Scrapy 2
Have you ever spent hours trying to gather high-quality data from specific websites, and wondered how you could extract this data programmatically and use it within your own applications? In this course, Crawling the Web with Python 3 and Scrapy 2, you will gain the ability to write spiders that can extract data from the web, using Python and Visual Studio Code, through an advanced yet easy-to-use framework called Scrapy. First, you will learn what scraping and crawling are, and explore all its implications. Next, you will discover how to scaffold a Scrapy project and write spiders. Finally, you will explore how to influence how spiders crawl websites and extract data in different formats. When you are finished with this course, you will have the skills and knowledge on how to use Scrapy with Python, to programmatically crawl and scrape data from any website.
###### Extracting Data from the Web – Core Concepts
###### Scaffolding and Running Your First Scrapy Web Crawler Project
###### Achieving Common Spider Behaviors Using Built-in Classes
###### Influencing Scrapy Crawling
###### Scrapy Outcome and Data Export

### Scraping Dynamic Web Pages with Python 3 and Selenium
They say data is the new oil, and given what you can do with high quality data, you'd be hard-pressed to disagree. There are many ways to collect data, one of which is extracting the oodles of data swimming around in the form of websites. That is exactly what this course, Scraping Dynamic Web Pages with Python 3 and Selenium, aims to teach. First, you are going to look at how to scrape data from dynamic websites. The main tool used is Selenium, and the course starts off by exploring that. Next, you will move onto the specifics of it, starting with opening a webpage using a web driver. Then you will learn to identify and locate dynamic elements in a webpage and handing the page source over to beautiful soup. Finally, to round off the course, you will explore the common challenges you will face and methods to increase scraping efficiency. When you are finished with this course, you will be able to combine Python, Selenium, and Beautiful Soup to extract data from any dynamic webpage.
###### Exploring Selenium with Python
###### Locating Elements & Navigating Dynamic Web Pages
###### Loading Selenium Page Source into BeautifulSoup
###### Overcoming Challenges and Increasing Efficiency

### Advanced Web Scraping Tactics: Python 3 Playbook
Scraping static, uncomplicated webpages is easy to do with Python. The going gets a little tougher though when you are confronted with things like login pages, checkboxes, and forms. In this course, Advanced Web Scraping Tactics: Python 3 Playbook, you will take what you already know about introductory web scraping and learn advanced web scraping techniques. First, you will learn what advanced web scraping means, followed by how to handle form submissions with the Python requests module and Selenium. Next, you will deal with how to handle websites with login pages and cookies, and how to provide button input values such as clicking checkboxes and radio buttons. Finally, you will use Selenium to upload files which will come in handy when you are required by websites to upload images, PDF files, and more to proceed further. When you are finished with this course, you will have the skills to navigate problems when trying to scrape data from websites.
###### Introducing Advanced Web Scraping & Handling Form Submissions
###### Submitting Cookies & Button Input Values to a URL
###### Uploading Files to a Webpage during Scraping

## Interpreting Data with Python
Interpreting Data with Python is a skill that will teach learners how to apply disciplines such as Statistics and Probability to understand data and to prep future models.

Find relationships in a data set and interpret data with simple statistical models using Python.

### Finding Relationships in Data with Python
Data science and data modeling are fast emerging as crucial capabilities that every enterprise and every technologist must possess these days. Increasingly, different organizations are using the same models and the same modeling tools, so what differs is how those models are applied to the data. Today, more than ever, it is really important that you know your data well. In this course, Finding Relationships in Data with Python you will gain the ability to find relationships within your data that you can exploit to construct more complex models. First, you will learn to summarize your data using univariate, bivariate and multivariate statistics. Next, you will discover how specific forms of visualization have evolved to identify and capture specific types of relationships. You will then learn some advanced tools such as the use of autocorrelation plots and KDE plots that help model probability distributions. Finally, you will round out your knowledge by using four of these libraries - Matplotlib, Seaborn, Altair and Plotly to find relationships. When you’re finished with this course, you will have the skills and knowledge to identify and exploit relationships that exist within your data, by efficiently exploring and visualizing that data.
###### Identifying and Visualizing Common Relationships in Data
###### New ModuleIdentifying and Visualizing Probabilistic and Statistical Relationships
###### Using Interactive Visualizations to Explore Relationships in Data

### Interpreting Data Using Statistical Models with Python
Data science and data modeling are fast emerging as crucial capabilities that every enterprise and every technologist must possess these days. Increasingly, different organizations are using the same models and modeling tools, so what differs is how those models are applied to the data. Today, more than ever, it is really important that you know your data well. In this course, Interpreting Data using Statistical Models with Python you will gain the ability to go one step beyond visualizations and basic descriptive statistics, by harnessing the power of inferential statistics. First, you will learn how hypothesis testing, which is the foundation of inferential statistics, helps posit and test assumptions about data. Next, you will discover how the classic t-test can be used in a variety of common scenarios around estimating means. You will also learn about related tests such as the Z-test, Pearson’s Chi-squared test, Levene’s test and Welch’s t-test for dealing with populations that have unequal variances. Finally, you will round out your knowledge by using ANOVA, a powerful statistical technique used to measure statistical properties across different categories of data. When you’re finished with this course, you will have the skills and knowledge to use powerful techniques from hypothesis testing, including t-tests, ANOVA and regression tests in order to measure the strength of statistical relationships within your data.
###### Understanding Inferential Statistics
###### Performing Hypothesis Testing in Python
###### Implementing Predictive Models for Continuous Data
###### Implementing Predictive Models for Categorical Data

Interpret data without models using Python by calculating common descriptive statistics for central tendency and variability.

### Interpreting Data Using Descriptive Statistics with Python
The tools of machine learning - algorithms, solution techniques, and even neural network architectures, are becoming commoditized. Everyone is using the same tools these days, so your edge needs to come from how well you adapt those tools to your data. In this course, Interpreting Data using Descriptive Statistics with Python, you will gain the ability to identify the important statistical properties of your dataset and understand their implications. First, you will explore how important measures of central tendency, the arithmetic mean, the mode, and the median, each summarize our data in different ways. Next, you will discover how measures of dispersion such as standard deviation provide clues about variation in a single variable. Later, you will learn how your data is distributed using skewness and kurtosis and understand bivariate measures of dispersion and co-movement like correlation and covariance. Finally, you will round out your knowledge by implementing these measures using different libraries available in Python, like Pandas, SciPy, and StatsModels. When you are finished with this course, you will have the skills and knowledge to summarize key statistical properties of your dataset using Python.
###### Understanding Descriptive Statistics
###### Working with Descriptive Statistics Using Pandas
###### Working with Descriptive Statistics Using SciPy and Statsmodels
